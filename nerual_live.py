import cv2
import torch
import torchvision.transforms as transforms
from transformer_net import TransformerNet
import os
import time

# Cesta k modelum
MODEL_PATHS = {
    '1': ("models/mosaic.pth", "Mosaic"),
    '2': ("models/candy.pth", "Candy"),
    '3': ("models/rain_princess.pth", "Rain Princess"),
    '4': ("models/starry-night.pth", "Starry night"),
    '5': ("models/udnie.pth", "Udnie"),
    '6': ("models/bayanihan.pth", "bayanihan")
}

# Aktu√°ln√≠ model
current_model_key = '1'
device = torch.device("mps" if torch.backends.mps.is_built() else "cpu")
print(f"üß† V√Ωpoƒçty pobƒõ≈æ√≠ na za≈ô√≠zen√≠: {device}")

# Slo≈æka pro ulo≈æen√≠ sn√≠mk≈Ø
output_dir = "snapshots"
os.makedirs(output_dir, exist_ok=True)

# Zji≈°tƒõn√≠ ƒç√≠taƒçe z existuj√≠c√≠ch soubor≈Ø
existing_files = [f for f in os.listdir(output_dir) if f.startswith("snapshot_") and f.endswith(".jpg")]
existing_numbers = [int(f.split("_")[1]) for f in existing_files if f.split("_")[1].isdigit()]
snapshot_counter = max(existing_numbers, default=0) + 1

# Naƒçten√≠ modelu
def load_model(model_path):
    style_model = TransformerNet()

    # V≈ædy naƒçti model do CPU
    state_dict = torch.load(model_path, map_location="cpu")

    # Odstranƒõn√≠ nepodporovan√Ωch kl√≠ƒç≈Ø z InstanceNorm2d
    ignored = [k for k in state_dict.keys() if "running_mean" in k or "running_var" in k]
    for k in ignored:
        del state_dict[k]

    # P≈ôejmenov√°n√≠ kl√≠ƒç≈Ø (pokud existuj√≠)
    for k in list(state_dict.keys()):
        if k.startswith("saved_model."):
            state_dict[k.replace("saved_model.", "")] = state_dict.pop(k)

    style_model.load_state_dict(state_dict, strict=False)
    style_model.to(device)
    style_model.eval()
    return style_model

print("\nüé® Stylizace pomoc√≠ neuronov√Ωch s√≠t√≠ (fast-neural-style)")
print("-------------------------------------------------------")
print("1 = Mosaic")
print("2 = Candy")
print("3 = Rain Princess")
print("4 = Starry night")
print("5 = Udnie")
print("s = Ulo≈æit sn√≠mek")
print("q = Ukonƒçit\n")

# Inicializace modelu
model, model_name = load_model(MODEL_PATHS[current_model_key][0]), MODEL_PATHS[current_model_key][1]

# Transformace vstupu
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Lambda(lambda x: x.mul(255))
])

# Kamera
cap = cv2.VideoCapture(0)


while True:
    ret, frame = cap.read()
    if not ret:
        break

    frame = cv2.flip(frame, 1)
    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    img_tensor = transform(img).unsqueeze(0).to(device)

    with torch.no_grad():
        output_tensor = model(img_tensor).cpu()

    output_data = output_tensor.squeeze().clamp(0, 255).detach().numpy()
    output_data = output_data.transpose(1, 2, 0).astype('uint8')
    output_bgr = cv2.cvtColor(output_data, cv2.COLOR_RGB2BGR)

    # üßº Vytvo≈ô√≠me ƒçistou verzi v√Ωstupu bez textu pro snapshot
    clean_output = output_bgr.copy()

    # P≈ôid√°me text pouze pro n√°hled v oknƒõ
    cv2.putText(output_bgr, f"Styl: {model_name}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)
    cv2.imshow("Stylizace", output_bgr)

    key = cv2.waitKey(1) & 0xFF

    if key == ord('q'):
        break
    elif key == ord('s'):
        filename = os.path.join(output_dir, f"snapshot_{snapshot_counter}_{model_name.lower().replace(' ', '_')}.jpg")
        cv2.imwrite(filename, clean_output)  # Ukl√°d√°me ƒçistou verzi
        print(f"üñºÔ∏è Ulo≈æen sn√≠mek jako {filename}")
        snapshot_counter += 1
    elif chr(key) in MODEL_PATHS:
        current_model_key = chr(key)
        model, model_name = load_model(MODEL_PATHS[current_model_key][0]), MODEL_PATHS[current_model_key][1]
        print(f"\nüîÅ P≈ôepnuto na styl: {model_name}")

cap.release()
cv2.destroyAllWindows()
